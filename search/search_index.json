{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Seg2Link Seg2Link is a program designed to semi-automatically segment 3D EM images. It takes an inaccurate deep learning cell/non-cell prediction as input and assists users in quickly transforming the prediction into accurate cell segmentation. Overview Data preparation Install and use Seg2Link Frequently asked questions Repository in GitHub","title":"Home"},{"location":"#welcome-to-seg2link","text":"Seg2Link is a program designed to semi-automatically segment 3D EM images. It takes an inaccurate deep learning cell/non-cell prediction as input and assists users in quickly transforming the prediction into accurate cell segmentation. Overview Data preparation Install and use Seg2Link Frequently asked questions Repository in GitHub","title":"Welcome to Seg2Link"},{"location":"FAQ/","text":"Frequently asked questions Q1: Is Seg2Link compatible with Windows/macOS/Linux? A1: Yes. Seg2Link can be used in any of these three operating systems, though their appearance in each differs slightly. Q2: The software crashes when I press a hotkey more than once. Why? A2: Requesting a new operation before the previous one has finished can cause the program to crash. Please wait until the previous instruction is completed. Q3: The layout of the main window is incorrect. Why? A3: One possible reason is that your monitor's resolution is insufficient. We recommend that users use a monitor with at least 1920 x 1080 resolution. The scale function in Windows could also cause problems. Try to modify or stop it to get an acceptable appearance. Q4: Do I need a GPU to use Seg2Link? A4: No, the core functions of Seg2Link are realized using numpy and numpy-based libraries, which rely solely on the CPU. However, keep in mind that in order to train a deep neural network to predict cell/non-cell regions, you may require a GPU PC or free GPU resources from sites like Google Colab.","title":"FAQ"},{"location":"FAQ/#frequently-asked-questions","text":"Q1: Is Seg2Link compatible with Windows/macOS/Linux? A1: Yes. Seg2Link can be used in any of these three operating systems, though their appearance in each differs slightly. Q2: The software crashes when I press a hotkey more than once. Why? A2: Requesting a new operation before the previous one has finished can cause the program to crash. Please wait until the previous instruction is completed. Q3: The layout of the main window is incorrect. Why? A3: One possible reason is that your monitor's resolution is insufficient. We recommend that users use a monitor with at least 1920 x 1080 resolution. The scale function in Windows could also cause problems. Try to modify or stop it to get an acceptable appearance. Q4: Do I need a GPU to use Seg2Link? A4: No, the core functions of Seg2Link are realized using numpy and numpy-based libraries, which rely solely on the CPU. However, keep in mind that in order to train a deep neural network to predict cell/non-cell regions, you may require a GPU PC or free GPU resources from sites like Google Colab.","title":"Frequently asked questions"},{"location":"overview/","text":"Segment cells with Seg2Link and Deep learning Problem Assume you have this 3D EM image dataset and want to segment it into individual cells. It is possible to manually annotate the cells in one or more slices one by one. However, when there are thousands of slices, manual annotation becomes impractical. Modern machine learning and deep learning methods could produce automatic segmentation, but the results could contain a large number of errors that must be corrected manually. Solution By using Seg2Link, you can quickly convert inaccurate deep learning or machine learning predictions to accurate segmentation results. Annotate a few subregions as cell/non cell manually : Typically, 20-30 subregions may be sufficient. With the annotated data, train a deep neural network or other machine learning models. Predict the cell/non-cell regions in the entire 3D image using the trained network: Input your prediction into Seg2Link . It will generate segmentations automatically and allow you to easily correct any errors:","title":"Overview"},{"location":"overview/#segment-cells-with-seg2link-and-deep-learning","text":"","title":"Segment cells with Seg2Link and Deep learning"},{"location":"overview/#problem","text":"Assume you have this 3D EM image dataset and want to segment it into individual cells. It is possible to manually annotate the cells in one or more slices one by one. However, when there are thousands of slices, manual annotation becomes impractical. Modern machine learning and deep learning methods could produce automatic segmentation, but the results could contain a large number of errors that must be corrected manually.","title":"Problem"},{"location":"overview/#solution","text":"By using Seg2Link, you can quickly convert inaccurate deep learning or machine learning predictions to accurate segmentation results. Annotate a few subregions as cell/non cell manually : Typically, 20-30 subregions may be sufficient. With the annotated data, train a deep neural network or other machine learning models. Predict the cell/non-cell regions in the entire 3D image using the trained network: Input your prediction into Seg2Link . It will generate segmentations automatically and allow you to easily correct any errors:","title":"Solution"},{"location":"quick_start/","text":"Install Seg2Link Install Anaconda or Miniconda Launch the Anaconda PowerShell Prompt in Windows or the terminal in macOS/Linux. Create a new conda environment with a custom name, such as seg2link-env, and activate it by running following commands: $ conda create -n seg2link-env python=3.8 pip $ conda activate seg2link-env Install Seg2Link: (seg2link-env) $ pip install seg2link Use Seg2Link Data preparation Before performing segmentation, you must have at least the following data: A 3D cell image saved in a folder as a set of 2D Tiff images. A cellular/non-cellular prediction based on 1, saved in a different folder as 2D Tiff images. Launch Seg2Link Activate the created environment and launch Seg2link: $ conda activate seg2link-env (seg2link-env) $ seg2link Screenshots Note I used an environment name seg2link rather than seg2link-env . An initial interface is displayed. Choose a module Choose a proper module from the initial interface to perform: the semi-automatic segmentation (in Module Seg2D+Link ) or the comprehensive 3D inspection and corrections (in Module 3D correction )","title":"Use Seg2Link"},{"location":"quick_start/#install-seg2link","text":"Install Anaconda or Miniconda Launch the Anaconda PowerShell Prompt in Windows or the terminal in macOS/Linux. Create a new conda environment with a custom name, such as seg2link-env, and activate it by running following commands: $ conda create -n seg2link-env python=3.8 pip $ conda activate seg2link-env Install Seg2Link: (seg2link-env) $ pip install seg2link","title":"Install Seg2Link"},{"location":"quick_start/#use-seg2link","text":"","title":"Use Seg2Link"},{"location":"quick_start/#data-preparation","text":"Before performing segmentation, you must have at least the following data: A 3D cell image saved in a folder as a set of 2D Tiff images. A cellular/non-cellular prediction based on 1, saved in a different folder as 2D Tiff images.","title":"Data preparation"},{"location":"quick_start/#launch-seg2link","text":"Activate the created environment and launch Seg2link: $ conda activate seg2link-env (seg2link-env) $ seg2link Screenshots Note I used an environment name seg2link rather than seg2link-env . An initial interface is displayed.","title":"Launch Seg2Link"},{"location":"quick_start/#choose-a-module","text":"Choose a proper module from the initial interface to perform: the semi-automatic segmentation (in Module Seg2D+Link ) or the comprehensive 3D inspection and corrections (in Module 3D correction )","title":"Choose a module"},{"location":"seg2link-unet2d/","text":"Prepare cell/non-cell predictions for Seg2Link We will show you how to predict cell/non-cell using free software/programs. However, you can also perform these tasks using other commercial or free software. 1. Prepare raw images You should prepare an image stack saved as 2D images of tiff format. Please note that currently our training program only supports grayscale image. Download the Demo data . 2. Annotate cells Here we describe the annotations with Fiji , but you can use any other tools you prefer for the annotation. Drag and drop one slice of the raw image into Fiji. Select a small subregion and crop: Save the cropped image as train_image0000.tif , under the directory train_image Double-click the paintbrush tool, and check the Paint on overlay Paint the non-cell regions After the painting is done, create a mask image from the overlay: Invert the mask image so that non-cell regions have a value of 0: Save the mask image as train_cells0000.tif , under the directory train_label Repeat above procedures to make 20 or more annotations. 3. Install the deep learning environment in local PC If you have a CUDA-enabled GPU, you can install the deep learning environment on your local PC . If not, you can skip this step and use the free GPU resource and deep learning environment in Google Colab . Install Anaconda or Miniconda Launch the Anaconda PowerShell Prompt in Windows or the terminal in macOS/Linux. Create a new conda environment with a custom name, such as unet2d, and activate it by running following commands: $ conda create -n unet2d $ conda activate unet2d Install Pytorch in the unet2d environment Install seg2Link-unet2d in the unet2d environment: (unet2d) $ pip install seg2Link-unet2d[local] 4. Launch the notebook for training 1) Launch the notebook in your local PC Right click to download the notebook ( link ) If the file is saved with .txt extension, change it to .ipynb. Move to the directory containing the notebook. (replace C:/xxx/xxx/ with the real path) (unet2d) $ cd C:/xxx/xxx/ Place your raw images and training data into a directory with a custom name such as unet_01 . The directory unet_01 should be placed in the same parent directory as the training notebook: C:/xxx/xxx \u251c\u2500\u2500\u2500Training_notebook_xxx.ipynb \u2514\u2500\u2500\u2500unet_01 \u251c\u2500\u2500\u2500raw_image \u2502 \u251c\u2500\u2500\u2500raw_image0000.tif \u2502 \u251c\u2500\u2500\u2500raw_image0001.tif \u2502 \u251c\u2500\u2500\u2500raw_image0002.tif \u2502 \u2514\u2500\u2500\u2500... \u251c\u2500\u2500\u2500train_image \u2502 \u251c\u2500\u2500\u2500train_image0000.tif \u2502 \u251c\u2500\u2500\u2500train_image0001.tif \u2502 \u251c\u2500\u2500\u2500train_image0002.tif \u2502 \u2514\u2500\u2500\u2500... \u2514\u2500\u2500\u2500train_label \u251c\u2500\u2500\u2500train_cells0000.tif \u251c\u2500\u2500\u2500train_cells0001.tif \u251c\u2500\u2500\u2500train_cells0002.tif \u2514\u2500\u2500\u2500... Launch the jupyter notebook (unet2d) $ jupyter notebook Open the notebook and proceed to step 5 below for training. 2) Launch the notebook in Google Colab Right click to download the notebook ( link ) If the file is saved with .txt extension, change it to .ipynb. Launch Google Colab and upload the downloaded notebook Enable GPUs in Google Colab: Navigate to Edit \u2192 Notebook Settings Select GPU from the Hardware Accelerator drop-down Place your raw images and training data into a directory with a custom name such as unet_01 . Upload unet_01 to the root of your Google drive: root of your Google drive \u2514\u2500\u2500\u2500unet_01 \u251c\u2500\u2500\u2500raw_image \u2502 \u251c\u2500\u2500\u2500raw_image0000.tif \u2502 \u251c\u2500\u2500\u2500raw_image0001.tif \u2502 \u251c\u2500\u2500\u2500raw_image0002.tif \u2502 \u2514\u2500\u2500\u2500... \u251c\u2500\u2500\u2500train_image \u2502 \u251c\u2500\u2500\u2500train_image0000.tif \u2502 \u251c\u2500\u2500\u2500train_image0001.tif \u2502 \u251c\u2500\u2500\u2500train_image0002.tif \u2502 \u2514\u2500\u2500\u2500... \u2514\u2500\u2500\u2500train_label \u251c\u2500\u2500\u2500train_cells0000.tif \u251c\u2500\u2500\u2500train_cells0001.tif \u251c\u2500\u2500\u2500train_cells0002.tif \u2514\u2500\u2500\u2500... Install seg2link-unet2d. Mount your Google drive. You'll be asked to give Google Colab permission to access your Google Drive. Proceed to step 5 below for training. 5. Train 2D U-Net The steps below apply to both local PCs and Google Colab. Run the code (Shift+Enter) to load packages. If no error occurs (warnings can be ignored), the seg2link-unet2d has been installed correctly. Initialize the trainer Load the training data Normalize the training data Divide images into subregions and apply augmentation Start training By default, you will apply 10 iterations x 3 times of training. But you can change the parameter iteration and apply more or less times of training. Everytime the accuracy is improved, the model will be saved, and the prediction will be updated and displayed. Results (Epochs 1-2) Results (Epochs 25-30) 6. Predict cell regions Load the model that was saved during training. You must replace the models_xxx in the path with the directory created when initializing the trainer. By default, the best model with the highest accuracy ( pretrained_unet3.pt ) will be loaded. But you can also choose a different model exist in the models_xxx directory (such like weights_training_epoch20.pt ). Calculate and display the prediction in a specified slice. If you are satisfied with the prediction, predict in all slices. The predictions will be saved into the directory raw_label under unet_01","title":"Data preparation"},{"location":"seg2link-unet2d/#prepare-cellnon-cell-predictions-for-seg2link","text":"We will show you how to predict cell/non-cell using free software/programs. However, you can also perform these tasks using other commercial or free software.","title":"Prepare cell/non-cell predictions for Seg2Link"},{"location":"seg2link-unet2d/#1-prepare-raw-images","text":"You should prepare an image stack saved as 2D images of tiff format. Please note that currently our training program only supports grayscale image. Download the Demo data .","title":"1. Prepare raw images"},{"location":"seg2link-unet2d/#2-annotate-cells","text":"Here we describe the annotations with Fiji , but you can use any other tools you prefer for the annotation. Drag and drop one slice of the raw image into Fiji. Select a small subregion and crop: Save the cropped image as train_image0000.tif , under the directory train_image Double-click the paintbrush tool, and check the Paint on overlay Paint the non-cell regions After the painting is done, create a mask image from the overlay: Invert the mask image so that non-cell regions have a value of 0: Save the mask image as train_cells0000.tif , under the directory train_label Repeat above procedures to make 20 or more annotations.","title":"2. Annotate cells"},{"location":"seg2link-unet2d/#3-install-the-deep-learning-environment-in-local-pc","text":"If you have a CUDA-enabled GPU, you can install the deep learning environment on your local PC . If not, you can skip this step and use the free GPU resource and deep learning environment in Google Colab . Install Anaconda or Miniconda Launch the Anaconda PowerShell Prompt in Windows or the terminal in macOS/Linux. Create a new conda environment with a custom name, such as unet2d, and activate it by running following commands: $ conda create -n unet2d $ conda activate unet2d Install Pytorch in the unet2d environment Install seg2Link-unet2d in the unet2d environment: (unet2d) $ pip install seg2Link-unet2d[local]","title":"3. Install the deep learning environment in local PC"},{"location":"seg2link-unet2d/#4-launch-the-notebook-for-training","text":"","title":"4. Launch the notebook for training"},{"location":"seg2link-unet2d/#1-launch-the-notebook-in-your-local-pc","text":"Right click to download the notebook ( link ) If the file is saved with .txt extension, change it to .ipynb. Move to the directory containing the notebook. (replace C:/xxx/xxx/ with the real path) (unet2d) $ cd C:/xxx/xxx/ Place your raw images and training data into a directory with a custom name such as unet_01 . The directory unet_01 should be placed in the same parent directory as the training notebook: C:/xxx/xxx \u251c\u2500\u2500\u2500Training_notebook_xxx.ipynb \u2514\u2500\u2500\u2500unet_01 \u251c\u2500\u2500\u2500raw_image \u2502 \u251c\u2500\u2500\u2500raw_image0000.tif \u2502 \u251c\u2500\u2500\u2500raw_image0001.tif \u2502 \u251c\u2500\u2500\u2500raw_image0002.tif \u2502 \u2514\u2500\u2500\u2500... \u251c\u2500\u2500\u2500train_image \u2502 \u251c\u2500\u2500\u2500train_image0000.tif \u2502 \u251c\u2500\u2500\u2500train_image0001.tif \u2502 \u251c\u2500\u2500\u2500train_image0002.tif \u2502 \u2514\u2500\u2500\u2500... \u2514\u2500\u2500\u2500train_label \u251c\u2500\u2500\u2500train_cells0000.tif \u251c\u2500\u2500\u2500train_cells0001.tif \u251c\u2500\u2500\u2500train_cells0002.tif \u2514\u2500\u2500\u2500... Launch the jupyter notebook (unet2d) $ jupyter notebook Open the notebook and proceed to step 5 below for training.","title":"1) Launch the notebook in your local PC"},{"location":"seg2link-unet2d/#2-launch-the-notebook-in-google-colab","text":"Right click to download the notebook ( link ) If the file is saved with .txt extension, change it to .ipynb. Launch Google Colab and upload the downloaded notebook Enable GPUs in Google Colab: Navigate to Edit \u2192 Notebook Settings Select GPU from the Hardware Accelerator drop-down Place your raw images and training data into a directory with a custom name such as unet_01 . Upload unet_01 to the root of your Google drive: root of your Google drive \u2514\u2500\u2500\u2500unet_01 \u251c\u2500\u2500\u2500raw_image \u2502 \u251c\u2500\u2500\u2500raw_image0000.tif \u2502 \u251c\u2500\u2500\u2500raw_image0001.tif \u2502 \u251c\u2500\u2500\u2500raw_image0002.tif \u2502 \u2514\u2500\u2500\u2500... \u251c\u2500\u2500\u2500train_image \u2502 \u251c\u2500\u2500\u2500train_image0000.tif \u2502 \u251c\u2500\u2500\u2500train_image0001.tif \u2502 \u251c\u2500\u2500\u2500train_image0002.tif \u2502 \u2514\u2500\u2500\u2500... \u2514\u2500\u2500\u2500train_label \u251c\u2500\u2500\u2500train_cells0000.tif \u251c\u2500\u2500\u2500train_cells0001.tif \u251c\u2500\u2500\u2500train_cells0002.tif \u2514\u2500\u2500\u2500... Install seg2link-unet2d. Mount your Google drive. You'll be asked to give Google Colab permission to access your Google Drive. Proceed to step 5 below for training.","title":"2) Launch the notebook in Google Colab"},{"location":"seg2link-unet2d/#5-train-2d-u-net","text":"The steps below apply to both local PCs and Google Colab. Run the code (Shift+Enter) to load packages. If no error occurs (warnings can be ignored), the seg2link-unet2d has been installed correctly. Initialize the trainer Load the training data Normalize the training data Divide images into subregions and apply augmentation Start training By default, you will apply 10 iterations x 3 times of training. But you can change the parameter iteration and apply more or less times of training. Everytime the accuracy is improved, the model will be saved, and the prediction will be updated and displayed. Results (Epochs 1-2) Results (Epochs 25-30)","title":"5. Train 2D U-Net"},{"location":"seg2link-unet2d/#6-predict-cell-regions","text":"Load the model that was saved during training. You must replace the models_xxx in the path with the directory created when initializing the trainer. By default, the best model with the highest accuracy ( pretrained_unet3.pt ) will be loaded. But you can also choose a different model exist in the models_xxx directory (such like weights_training_epoch20.pt ). Calculate and display the prediction in a specified slice. If you are satisfied with the prediction, predict in all slices. The predictions will be saved into the directory raw_label under unet_01","title":"6. Predict cell regions"},{"location":"Round1/delete/","text":"Delete Delete a single cell Select a cell in Pick Mode . Press D to delete the selected cell. Delete multiple cells Select multiple cells and add them into the label list (See procedures 1 and 2 in Merge section) Press D to delete the cells in the label list. Note : To clean the label list before deleting, press C .","title":"Delete cells"},{"location":"Round1/delete/#delete","text":"","title":"Delete"},{"location":"Round1/delete/#delete-a-single-cell","text":"Select a cell in Pick Mode . Press D to delete the selected cell.","title":"Delete a single cell"},{"location":"Round1/delete/#delete-multiple-cells","text":"Select multiple cells and add them into the label list (See procedures 1 and 2 in Merge section) Press D to delete the cells in the label list. Note : To clean the label list before deleting, press C .","title":"Delete multiple cells"},{"location":"Round1/divide/","text":"Division Defination/Notes Current working slice : In Seg2D+Link Module, segmentation was generated and corrected sequentially. At a specific time point, the slice i and the previous slices have been segmented, while slices after i have not been processed yet. We define the slice i as the current working slice. Because of the special data structure used in Seg2D+Link Module, the Division and Division+Relink can only be applied to current working slice. Procedures Find a label that requires division, in the current working slice. If necessary, zoom in ( Space + Mouse scroll wheel ) to view the local regions. Select the tool Eraser by pressing E . Adjust the brush size. Then edit the cell boundary. Switch to the Picker Mode by pressing L . Click the cell to be divided. Then press K to divide the cell in the slice into multiple new cells. If neccesary, use other commands such as Merge and Delete to further modify the result.","title":"Divide a cell"},{"location":"Round1/divide/#division","text":"","title":"Division"},{"location":"Round1/divide/#definationnotes","text":"Current working slice : In Seg2D+Link Module, segmentation was generated and corrected sequentially. At a specific time point, the slice i and the previous slices have been segmented, while slices after i have not been processed yet. We define the slice i as the current working slice. Because of the special data structure used in Seg2D+Link Module, the Division and Division+Relink can only be applied to current working slice.","title":"Defination/Notes"},{"location":"Round1/divide/#procedures","text":"Find a label that requires division, in the current working slice. If necessary, zoom in ( Space + Mouse scroll wheel ) to view the local regions. Select the tool Eraser by pressing E . Adjust the brush size. Then edit the cell boundary. Switch to the Picker Mode by pressing L . Click the cell to be divided. Then press K to divide the cell in the slice into multiple new cells. If neccesary, use other commands such as Merge and Delete to further modify the result.","title":"Procedures"},{"location":"Round1/divide_relink/","text":"Division+Relink When a label is correctly segmented in slice i but not in slice i+1, you can use Division+Relink to divide and link cells automatically, which is much more efficient than Division + manual linking. Before operation: Slice 1: Slice 2: Correct the cell boundary in slice 2 (See procedures 2 and 3 in Division ). Switch to the Picker Mode by pressing L . Click the cell to be divided and then press R . Now the cell in slice 2 has been divided and correctly linked to the cells in slice 1!","title":"Divide + Relink"},{"location":"Round1/divide_relink/#divisionrelink","text":"When a label is correctly segmented in slice i but not in slice i+1, you can use Division+Relink to divide and link cells automatically, which is much more efficient than Division + manual linking. Before operation: Slice 1: Slice 2: Correct the cell boundary in slice 2 (See procedures 2 and 3 in Division ). Switch to the Picker Mode by pressing L . Click the cell to be divided and then press R . Now the cell in slice 2 has been divided and correctly linked to the cells in slice 1!","title":"Division+Relink"},{"location":"Round1/export/","text":"Export 3D segmentation result After you've finished the semi-automatic segmentations in all slices, press the button \"Export segmentation as .npy file\" to export the 3D segmentation as a 3D array file (.npy format). By default, the result is saved in the folder that the user has previously specified in the parameter setting . We advise users not to change the folder.","title":"Export as 3D array"},{"location":"Round1/export/#export-3d-segmentation-result","text":"After you've finished the semi-automatic segmentations in all slices, press the button \"Export segmentation as .npy file\" to export the 3D segmentation as a 3D array file (.npy format). By default, the result is saved in the folder that the user has previously specified in the parameter setting . We advise users not to change the folder.","title":"Export 3D segmentation result"},{"location":"Round1/merge/","text":"Merge cells In Pick Mode , click a cell with the left mouse button to select it. Then, press A to add the cell to the label list (in the State info panel). Repeat step 1 to add more cells. Press M to merge the cells in the label list Note : To clean the label list before applying merge, press C .","title":"Merge cells"},{"location":"Round1/merge/#merge-cells","text":"In Pick Mode , click a cell with the left mouse button to select it. Then, press A to add the cell to the label list (in the State info panel). Repeat step 1 to add more cells. Press M to merge the cells in the label list Note : To clean the label list before applying merge, press C .","title":"Merge cells"},{"location":"Round1/next/","text":"Next slice Correct all errors in current working slice i . Then you can go to the next slice i + 1 Before operation Slice 1 Press Shift + N Slice 2 Now the slice 2 has been automatically segmented and linked to slice 1.","title":"Next slice"},{"location":"Round1/next/#next-slice","text":"Correct all errors in current working slice i . Then you can go to the next slice i + 1 Before operation Slice 1 Press Shift + N Slice 2 Now the slice 2 has been automatically segmented and linked to slice 1.","title":"Next slice"},{"location":"Round1/panel_description/","text":"Panels description Panels 1. Layer controls This is a default panel in napari viewer for viewing/editing a label layer (segmentation layer). Here are some key features: Picker mode: You can select a label by clicking it with mouse. Press L to change to this mode. Pan/Zoom: You can hold space key and use left button/wheel of mouse to pan/zoom the image in Picker mode. Eraser: You can set a pixel as non-cell region (set the value to 0) with the eraser tool. Press E to change to this tool. Paint brush: You can paint a region with a specific label. Press P to change to this tool. Shuffle colors: Two neighboring cells can occasionally be assigned the same color. To shuffle the colors, press this button (top leftmost). 2. Layer list You can select a layer from segmentation, cell/non-cell image, raw image, etc., and can hide or change the opacity of them. 3. Tools for change the view point The most import function here is the \"home\" function (rightmost), which allows you to resize the image to see the entire image. 4. Current layer/cursor position/selected label This panel is not used in this module, but it is useful in Module 3D correction. 5. Canvas (Segmentation results) The segmentation results and other reference images are shown here. The slice number of the currently displayed one can be easily calculated using the information surrounding the slide bar. E.g, \"Slice(1-50)\" together with \"12|49\" indicate current slice number = 1 + 12 = 13. 6. States Three types of information are shown here: The size of the 3D image. The largest cell ID in current segmentation result. The cached states that can be retrieved using undo/redo (By default, 10 steps in maximum). 7. Hotkeys information The (default) hotkeys used in Seg2D+Link module. 8. Export Export the 3D segmentation result. 9. State info Show information of current state such like: Performing operation xxx...; Operation xxx was done; Warning message: xxx; etc. IMPORTANT : To avoid software crashes, always ensure that the previous operation is finished before starting the next.d","title":"Panel description"},{"location":"Round1/panel_description/#panels-description","text":"","title":"Panels description"},{"location":"Round1/panel_description/#panels","text":"","title":"Panels"},{"location":"Round1/panel_description/#1-layer-controls","text":"This is a default panel in napari viewer for viewing/editing a label layer (segmentation layer). Here are some key features: Picker mode: You can select a label by clicking it with mouse. Press L to change to this mode. Pan/Zoom: You can hold space key and use left button/wheel of mouse to pan/zoom the image in Picker mode. Eraser: You can set a pixel as non-cell region (set the value to 0) with the eraser tool. Press E to change to this tool. Paint brush: You can paint a region with a specific label. Press P to change to this tool. Shuffle colors: Two neighboring cells can occasionally be assigned the same color. To shuffle the colors, press this button (top leftmost).","title":"1. Layer controls"},{"location":"Round1/panel_description/#2-layer-list","text":"You can select a layer from segmentation, cell/non-cell image, raw image, etc., and can hide or change the opacity of them.","title":"2. Layer list"},{"location":"Round1/panel_description/#3-tools-for-change-the-view-point","text":"The most import function here is the \"home\" function (rightmost), which allows you to resize the image to see the entire image.","title":"3. Tools for change the view point"},{"location":"Round1/panel_description/#4-current-layercursor-positionselected-label","text":"This panel is not used in this module, but it is useful in Module 3D correction.","title":"4. Current layer/cursor position/selected label"},{"location":"Round1/panel_description/#5-canvas-segmentation-results","text":"The segmentation results and other reference images are shown here. The slice number of the currently displayed one can be easily calculated using the information surrounding the slide bar. E.g, \"Slice(1-50)\" together with \"12|49\" indicate current slice number = 1 + 12 = 13.","title":"5. Canvas (Segmentation results)"},{"location":"Round1/panel_description/#6-states","text":"Three types of information are shown here: The size of the 3D image. The largest cell ID in current segmentation result. The cached states that can be retrieved using undo/redo (By default, 10 steps in maximum).","title":"6. States"},{"location":"Round1/panel_description/#7-hotkeys-information","text":"The (default) hotkeys used in Seg2D+Link module.","title":"7. Hotkeys information"},{"location":"Round1/panel_description/#8-export","text":"Export the 3D segmentation result.","title":"8. Export"},{"location":"Round1/panel_description/#9-state-info","text":"Show information of current state such like: Performing operation xxx...; Operation xxx was done; Warning message: xxx; etc. IMPORTANT : To avoid software crashes, always ensure that the previous operation is finished before starting the next.d","title":"9. State info"},{"location":"Round1/parameter_setting/","text":"Specify images/parameters in Seg2D+Link Parameter panels 1. Paths of images/results Users should specify three folders: containing the cell/non-cell prediction images (2D Tiff images); containing the raw images (2D Tiff images); to store the segmentation results. 2. Parameters Users should specify following parameters: Slice number to be retrieved. Default value is the last slice that have been segmented. The segmentation results after the specified slice number will be deleted. If set it to 0, the program will restart the segmentation and remove all previous segmentation results. Value of the cell region. Set it according to the cell/non-cell images. The minimal overlap coefficient. This is a custom threshold used for linking cells across slices. Supposing there are two cells X and Y in two adjacent slices, their overlap coefficient is: $$overlap(X,Y)=\\frac{Area(X\\cap Y)}{min(Area(X),Area(Y))} $$ If \\(overlap(X, Y) > threshold\\) , cells X and Y will be linked. 3. Save/Load the paths/parameters Users can save the specified parameters in a .ini file and reload it later to avoid having to set the paths/parameters every time the software is launched. 4. Use Mask images This option allows users to segment cells in regions of interest (ROI) defined by users. When it is selected, the GUI will change as follows: Users should further specify following parameters: Fill holes. Force the program to automatically fill the holes in the user-defined ROI. The calculation will take a long time when processing large image (but only once). Update cache of mask. The cache is a .npy file of the original/holes-filled mask image. It was created to avoid repeated calculations after launching the software. Check this option will force the program to re-make the cache file, which will take a long time. If it is not checked, the program will try to load the mask data from the existed cache file. Path for mask images. Specify the folder containing the mask images (2D Tiff images); Value of the mask region. Set this to the value of the user-defined ROI in mask images. The minimal overlap. This is a custom threshold for ignoring cells outside of the ROI.. Assuming a cell A was partially located within the ROI, then the overlap of A within ROI is: $$overlap(A)=\\frac{Area(X\\cap ROI)}{Area(A)} $$ If \\(overlap(A) < threshold\\) , Cell A will be removed from the segmentation result. 5. Warning information If the images or specified folders are not found, the warning information will be displayed here. 6. Start the Seg2D+Link Module Press this button to launch the Seg2D+Link module.","title":"Parameters description"},{"location":"Round1/parameter_setting/#specify-imagesparameters-in-seg2dlink","text":"","title":"Specify images/parameters in Seg2D+Link"},{"location":"Round1/parameter_setting/#parameter-panels","text":"","title":"Parameter panels"},{"location":"Round1/parameter_setting/#1-paths-of-imagesresults","text":"Users should specify three folders: containing the cell/non-cell prediction images (2D Tiff images); containing the raw images (2D Tiff images); to store the segmentation results.","title":"1. Paths of images/results"},{"location":"Round1/parameter_setting/#2-parameters","text":"Users should specify following parameters: Slice number to be retrieved. Default value is the last slice that have been segmented. The segmentation results after the specified slice number will be deleted. If set it to 0, the program will restart the segmentation and remove all previous segmentation results. Value of the cell region. Set it according to the cell/non-cell images. The minimal overlap coefficient. This is a custom threshold used for linking cells across slices. Supposing there are two cells X and Y in two adjacent slices, their overlap coefficient is: $$overlap(X,Y)=\\frac{Area(X\\cap Y)}{min(Area(X),Area(Y))} $$ If \\(overlap(X, Y) > threshold\\) , cells X and Y will be linked.","title":"2. Parameters"},{"location":"Round1/parameter_setting/#3-saveload-the-pathsparameters","text":"Users can save the specified parameters in a .ini file and reload it later to avoid having to set the paths/parameters every time the software is launched.","title":"3. Save/Load the paths/parameters"},{"location":"Round1/parameter_setting/#4-use-mask-images","text":"This option allows users to segment cells in regions of interest (ROI) defined by users. When it is selected, the GUI will change as follows: Users should further specify following parameters: Fill holes. Force the program to automatically fill the holes in the user-defined ROI. The calculation will take a long time when processing large image (but only once). Update cache of mask. The cache is a .npy file of the original/holes-filled mask image. It was created to avoid repeated calculations after launching the software. Check this option will force the program to re-make the cache file, which will take a long time. If it is not checked, the program will try to load the mask data from the existed cache file. Path for mask images. Specify the folder containing the mask images (2D Tiff images); Value of the mask region. Set this to the value of the user-defined ROI in mask images. The minimal overlap. This is a custom threshold for ignoring cells outside of the ROI.. Assuming a cell A was partially located within the ROI, then the overlap of A within ROI is: $$overlap(A)=\\frac{Area(X\\cap ROI)}{Area(A)} $$ If \\(overlap(A) < threshold\\) , Cell A will be removed from the segmentation result.","title":"4. Use Mask images"},{"location":"Round1/parameter_setting/#5-warning-information","text":"If the images or specified folders are not found, the warning information will be displayed here.","title":"5. Warning information"},{"location":"Round1/parameter_setting/#6-start-the-seg2dlink-module","text":"Press this button to launch the Seg2D+Link module.","title":"6. Start the Seg2D+Link Module"},{"location":"Round1/start_r1/","text":"Workflow of round 1 Specify the images and the parameters ( Detailed instructions ) Launch the main window of Seg2D+Link ( Panel descriptions ) Perform semi-automatic segmentations with following procedures: Correct the segmentation in slice i with following operations: Merge / Delete / Division / Division-Relink . Generate automatic segmentation in the Next slice i . Note : The incorrect operations in 1 and 2 can be canceled with undo/redo (Press U or F ). Repeat 1 and 2 until all slices are segmented and linked. Export the segmentation as a .npy file.","title":"Workflow"},{"location":"Round1/start_r1/#workflow-of-round-1","text":"Specify the images and the parameters ( Detailed instructions ) Launch the main window of Seg2D+Link ( Panel descriptions ) Perform semi-automatic segmentations with following procedures: Correct the segmentation in slice i with following operations: Merge / Delete / Division / Division-Relink . Generate automatic segmentation in the Next slice i . Note : The incorrect operations in 1 and 2 can be canceled with undo/redo (Press U or F ). Repeat 1 and 2 until all slices are segmented and linked. Export the segmentation as a .npy file.","title":"Workflow of round 1"},{"location":"Round2/delete/","text":"Delete The procedures are exactly the same as Delete in Round 1","title":"Delete cells"},{"location":"Round2/delete/#delete","text":"The procedures are exactly the same as Delete in Round 1","title":"Delete"},{"location":"Round2/divide/","text":"Division / Division + Relink (2D) Division The label 76 in slice 1 should be divided into 3 cells. Choose 2D mode and max division = Inf . Click the label 76 in Picker Mode . Then press K to divide it. The label was over-segmented with 2D watershed algorithm. If necessary, correct the cell boundary before pressing K to more precisely divide the cell. Correct the over-segmentation by Merge . Division+Relink The label 76 in slice 1 has been divided into 3 cells, but the same label in slice 2 requires similar division. Click the label 76 in Picker Mode . Then press R to divide it and relink the results to slice 1. The over-segmentation was solved automatically by relinking. The label 76 in slice 3 also requires similar division. Similarly, press R solves the problem.","title":"Divide / Division-Relink (2D)"},{"location":"Round2/divide/#division-division-relink-2d","text":"","title":"Division / Division + Relink (2D)"},{"location":"Round2/divide/#division","text":"The label 76 in slice 1 should be divided into 3 cells. Choose 2D mode and max division = Inf . Click the label 76 in Picker Mode . Then press K to divide it. The label was over-segmented with 2D watershed algorithm. If necessary, correct the cell boundary before pressing K to more precisely divide the cell. Correct the over-segmentation by Merge .","title":"Division"},{"location":"Round2/divide/#divisionrelink","text":"The label 76 in slice 1 has been divided into 3 cells, but the same label in slice 2 requires similar division. Click the label 76 in Picker Mode . Then press R to divide it and relink the results to slice 1. The over-segmentation was solved automatically by relinking. The label 76 in slice 3 also requires similar division. Similarly, press R solves the problem.","title":"Division+Relink"},{"location":"Round2/divide_3d/","text":"Division (3D) Divide a cell based on 3D connectivity. It should be used in following two cases: Divide incorrect merged cells that are spatially separated The label 2 should be divided into two cells due to the careless incorrect merge operation by the user. Choose 3D mode . Click the label 2 in Picker Mode . Then press K to divide it. The label was correctly divided into two cells. Divide two cells connected along z-axis Here are three slices of label 36. Suppose we need to divide it into two cells, with slice 10 as the boundary. Slice 9 Slice 10 Slice 11 Move to slice 10. Use bucket tool to fill the cell region with label 0 (i.e. as boundary) Go back to slice 9. Click label 36. Press K in 3D mode. Slice 9 Slice 10 Slice 11 The label 36 has been divided into two cells along z-axis!","title":"Divide a cell (3D)"},{"location":"Round2/divide_3d/#division-3d","text":"Divide a cell based on 3D connectivity. It should be used in following two cases:","title":"Division (3D)"},{"location":"Round2/divide_3d/#divide-incorrect-merged-cells-that-are-spatially-separated","text":"The label 2 should be divided into two cells due to the careless incorrect merge operation by the user. Choose 3D mode . Click the label 2 in Picker Mode . Then press K to divide it. The label was correctly divided into two cells.","title":"Divide incorrect merged cells that are spatially separated"},{"location":"Round2/divide_3d/#divide-two-cells-connected-along-z-axis","text":"Here are three slices of label 36. Suppose we need to divide it into two cells, with slice 10 as the boundary. Slice 9 Slice 10 Slice 11 Move to slice 10. Use bucket tool to fill the cell region with label 0 (i.e. as boundary) Go back to slice 9. Click label 36. Press K in 3D mode. Slice 9 Slice 10 Slice 11 The label 36 has been divided into two cells along z-axis!","title":"Divide two cells connected along z-axis"},{"location":"Round2/insert/","text":"Insert a cell Procedure Suppose you want to paint a new cell in the background region (gray region). Press I . The program will automatically switch to the Paint mode and create a new label, 571. Paint the cell region with the paint brush tool. Similarly, move to slice 2. And paint cell regions with the paint brush tool. Note: How to cancel the insert Currently, the Insert operation cannot be cancelled with undo/redo. If the inserted cell is not required, you can delete it by pressing D .","title":"Insert a cell"},{"location":"Round2/insert/#insert-a-cell","text":"","title":"Insert a cell"},{"location":"Round2/insert/#procedure","text":"Suppose you want to paint a new cell in the background region (gray region). Press I . The program will automatically switch to the Paint mode and create a new label, 571. Paint the cell region with the paint brush tool. Similarly, move to slice 2. And paint cell regions with the paint brush tool.","title":"Procedure"},{"location":"Round2/insert/#note-how-to-cancel-the-insert","text":"Currently, the Insert operation cannot be cancelled with undo/redo. If the inserted cell is not required, you can delete it by pressing D .","title":"Note: How to cancel the insert"},{"location":"Round2/localize/","text":"Locate a cell The localization function very useful when the cells have been sorted according to their importance (size). In such condition, users can selectively inspect and correct these more important cells. The segmentation shown below has been processed with sort + remove tiny cells . Select the cell whose label = 1 (the largest cell). Press the button Locate . The view jumps to the slice containing the cell center Press Q to view the selected label and hide other labels. The [x, y] coordinates of the cell center can be found after the Locate button. The [x, y, z] coordinates of the cursor can be found at left-bottom. This coordinates information can help users to find a tiny cell that is hard to see. You can locate another cell by modifying the Select label and pressing Locate again. Cell 2 is found To view all cells, press Q again.","title":"Localize a cell"},{"location":"Round2/localize/#locate-a-cell","text":"The localization function very useful when the cells have been sorted according to their importance (size). In such condition, users can selectively inspect and correct these more important cells. The segmentation shown below has been processed with sort + remove tiny cells . Select the cell whose label = 1 (the largest cell). Press the button Locate . The view jumps to the slice containing the cell center Press Q to view the selected label and hide other labels. The [x, y] coordinates of the cell center can be found after the Locate button. The [x, y, z] coordinates of the cursor can be found at left-bottom. This coordinates information can help users to find a tiny cell that is hard to see. You can locate another cell by modifying the Select label and pressing Locate again. Cell 2 is found To view all cells, press Q again.","title":"Locate a cell"},{"location":"Round2/merge/","text":"Merge cells The procedures are exactly the same as Merge in Round 1","title":"Merge cells"},{"location":"Round2/merge/#merge-cells","text":"The procedures are exactly the same as Merge in Round 1","title":"Merge cells"},{"location":"Round2/panel_description/","text":"Panels description Panels Panels 1, 2, 3, 5, 7, and 9 See descriptions of in round 1 . 4. Current layer [cursor position] selected label Together with the Localize function, the information of cursor position here can assist users in locating a cell. 6. States Four types of information/functions are shown here: The largest cell ID in current segmentation result. The cached states that can be retrieved with undo/redo. Select a cell ID and locate its position. See Localize The contents of the label list, used in Merge and Delete 8. Divide a single cell Mode 2D: Divide / Divide-Relink a cell in a specific slice. 3D: Divide a cell in 3D space . Max division Only used in 2D mode . The max number of cells allowed in the division result. If more cells are obtained, smaller cells will be merged with nearby cells. Inf means no limitation of the cell number. Divide cell Show information of division result. Check it Select a cell in the division result and jump to the slice containing its center. 10. Save/Export Save segmentation Save: Save the current result as seg-modified.npy. Save as: Save the current result with a custom filename. Load segmentation Load the segmentation result saved as npy format. Sort labels and remove tiny cells Export segmentation as .tiff files","title":"Panel description"},{"location":"Round2/panel_description/#panels-description","text":"","title":"Panels description"},{"location":"Round2/panel_description/#panels","text":"","title":"Panels"},{"location":"Round2/panel_description/#panels-1-2-3-5-7-and-9","text":"See descriptions of in round 1 .","title":"Panels 1, 2, 3, 5, 7, and 9"},{"location":"Round2/panel_description/#4-current-layer-cursor-position-selected-label","text":"Together with the Localize function, the information of cursor position here can assist users in locating a cell.","title":"4. Current layer [cursor position] selected label"},{"location":"Round2/panel_description/#6-states","text":"Four types of information/functions are shown here: The largest cell ID in current segmentation result. The cached states that can be retrieved with undo/redo. Select a cell ID and locate its position. See Localize The contents of the label list, used in Merge and Delete","title":"6. States"},{"location":"Round2/panel_description/#8-divide-a-single-cell","text":"Mode 2D: Divide / Divide-Relink a cell in a specific slice. 3D: Divide a cell in 3D space . Max division Only used in 2D mode . The max number of cells allowed in the division result. If more cells are obtained, smaller cells will be merged with nearby cells. Inf means no limitation of the cell number. Divide cell Show information of division result. Check it Select a cell in the division result and jump to the slice containing its center.","title":"8. Divide a single cell"},{"location":"Round2/panel_description/#10-saveexport","text":"Save segmentation Save: Save the current result as seg-modified.npy. Save as: Save the current result with a custom filename. Load segmentation Load the segmentation result saved as npy format. Sort labels and remove tiny cells Export segmentation as .tiff files","title":"10. Save/Export"},{"location":"Round2/parameter_setting/","text":"Specify images/parameters in 3D correction Parameter panels 1. Save/Load the configurations Users can save the specified parameters in a configuration (.ini) file and reload it later to avoid having to set them every time the software is launched. Users can load the same configuration file used in the Seg2D+Link module to reuse the shared parameters. 2. Use xxx images There are three options: Use the Mask images Check it if you want to display the mask image. If the configuration file is loaded from Round 1 that does not use mask images, this option becomes invisible. Use the Cell-region images Check it if you want to display the predictions of the cell/non-cell regions. Use image sequence as segmentation Check it if you want to use 3D segmentation which is generated from other software and is saved as 2D TIFF images. Do not check it if you have used Seg2D+Link module and saved the 3D segmentation result in npy format. 3. Paths of images / segmentation results Users should specify following paths: The folder containing the cell/non-cell prediction images (2D TIFF images); The folder containing the raw images (2D TIFF images); The path to the previously created segmentation results file. Uncheck the box in 2-3 to use the segmentation result in npy format. Check the box in 2-3 to use the segmentation result saved as 2D TIFF images. The folder containing the mask images (2D TIFF images). This option is only available if you checked the box in 2-1 . 4. Parameters & Warning The parameter (value of cell region) and warning here are similar to the ones in Parameters and Warning in Round 1. 5. Start the 3D correction Module Press this button to launch the 3D correction module.","title":"Parameters description"},{"location":"Round2/parameter_setting/#specify-imagesparameters-in-3d-correction","text":"","title":"Specify images/parameters in 3D correction"},{"location":"Round2/parameter_setting/#parameter-panels","text":"","title":"Parameter panels"},{"location":"Round2/parameter_setting/#1-saveload-the-configurations","text":"Users can save the specified parameters in a configuration (.ini) file and reload it later to avoid having to set them every time the software is launched. Users can load the same configuration file used in the Seg2D+Link module to reuse the shared parameters.","title":"1. Save/Load the configurations"},{"location":"Round2/parameter_setting/#2-use-xxx-images","text":"There are three options: Use the Mask images Check it if you want to display the mask image. If the configuration file is loaded from Round 1 that does not use mask images, this option becomes invisible. Use the Cell-region images Check it if you want to display the predictions of the cell/non-cell regions. Use image sequence as segmentation Check it if you want to use 3D segmentation which is generated from other software and is saved as 2D TIFF images. Do not check it if you have used Seg2D+Link module and saved the 3D segmentation result in npy format.","title":"2. Use xxx images"},{"location":"Round2/parameter_setting/#3-paths-of-images-segmentation-results","text":"Users should specify following paths: The folder containing the cell/non-cell prediction images (2D TIFF images); The folder containing the raw images (2D TIFF images); The path to the previously created segmentation results file. Uncheck the box in 2-3 to use the segmentation result in npy format. Check the box in 2-3 to use the segmentation result saved as 2D TIFF images. The folder containing the mask images (2D TIFF images). This option is only available if you checked the box in 2-1 .","title":"3. Paths of images / segmentation results"},{"location":"Round2/parameter_setting/#4-parameters-warning","text":"The parameter (value of cell region) and warning here are similar to the ones in Parameters and Warning in Round 1.","title":"4. Parameters &amp; Warning"},{"location":"Round2/parameter_setting/#5-start-the-3d-correction-module","text":"Press this button to launch the 3D correction module.","title":"5. Start the 3D correction Module"},{"location":"Round2/save_load_export/","text":"Save/Load/Export Save and Load Because saving the intermediate result is time-consuming in 3D correction, the program does not save it automatically. Instead, users must manually save the intermediate results after a certain amount of correction is completed. 1. Save When you have finished a certain number of corrections in the 3D correction module, press the Save button. The program will save the current result as \"seg-modified.npy.\" The old file will be overwritten. 2. Save as When you need to save the segmentation results into a different file to avoid overwriting an old file, click the Save as button 3. Load When you need to load a segmentation result saved previously, click the Load segmentation button, choose the file you need, and then click the open button. Export To export the result, click the Export button and then click Select Folder . The program will create a sub-folder called \"seg-tiff\" in which the exported 2D TIFF images will be saved. We recommend saving the exported results to the default folder to avoid confusion","title":"Save/Load/Export"},{"location":"Round2/save_load_export/#saveloadexport","text":"","title":"Save/Load/Export"},{"location":"Round2/save_load_export/#save-and-load","text":"Because saving the intermediate result is time-consuming in 3D correction, the program does not save it automatically. Instead, users must manually save the intermediate results after a certain amount of correction is completed.","title":"Save and Load"},{"location":"Round2/save_load_export/#1-save","text":"When you have finished a certain number of corrections in the 3D correction module, press the Save button. The program will save the current result as \"seg-modified.npy.\" The old file will be overwritten.","title":"1. Save"},{"location":"Round2/save_load_export/#2-save-as","text":"When you need to save the segmentation results into a different file to avoid overwriting an old file, click the Save as button","title":"2. Save as"},{"location":"Round2/save_load_export/#3-load","text":"When you need to load a segmentation result saved previously, click the Load segmentation button, choose the file you need, and then click the open button.","title":"3. Load"},{"location":"Round2/save_load_export/#export","text":"To export the result, click the Export button and then click Select Folder . The program will create a sub-folder called \"seg-tiff\" in which the exported 2D TIFF images will be saved. We recommend saving the exported results to the default folder to avoid confusion","title":"Export"},{"location":"Round2/sort_remove/","text":"Sort and remove tiny cells Sort labels by their sizes Press the button \"Sort labels and remove tiny cells\". Do not adjust the slide bar \"Max cell number\", unless you want to remove tiny cells . Press the button \"Save the sorted cells (.npy)\". The labels have been sorted according to their sizes!! Remove tiny cells Press the button \"Sort labels and remove tiny cells\", and adjust the \"Max cell number\" to 300. The cells < 63 voxels will be removed! Press the button \"Save the sorted cells (.npy)\". In the updated result, only 300 sorted larger cells were kept!! You can inspect these larger cells with Locate Notes: How to go back Because all of the voxels must be updated, caching the sorting operation requires a large amount of memory, which should be avoided. To solve the problem, the segmentations before and after the operation are automatically saved as two files on the hard disk: seg-modified_before_sort_remove.npy seg-modified_after_sort_remove.npy If users are unsatisfied with the result, reload the state before sorting/removing with Load function. After applying sorting/removing operation, the cache of the operations will be reset. Users cannot use undo/redo to return to even earlier states.","title":"Sort and remove tiny cells"},{"location":"Round2/sort_remove/#sort-and-remove-tiny-cells","text":"","title":"Sort and remove tiny cells"},{"location":"Round2/sort_remove/#sort-labels-by-their-sizes","text":"Press the button \"Sort labels and remove tiny cells\". Do not adjust the slide bar \"Max cell number\", unless you want to remove tiny cells . Press the button \"Save the sorted cells (.npy)\". The labels have been sorted according to their sizes!!","title":"Sort labels by their sizes"},{"location":"Round2/sort_remove/#remove-tiny-cells","text":"Press the button \"Sort labels and remove tiny cells\", and adjust the \"Max cell number\" to 300. The cells < 63 voxels will be removed! Press the button \"Save the sorted cells (.npy)\". In the updated result, only 300 sorted larger cells were kept!! You can inspect these larger cells with Locate","title":"Remove tiny cells"},{"location":"Round2/sort_remove/#notes-how-to-go-back","text":"Because all of the voxels must be updated, caching the sorting operation requires a large amount of memory, which should be avoided. To solve the problem, the segmentations before and after the operation are automatically saved as two files on the hard disk: seg-modified_before_sort_remove.npy seg-modified_after_sort_remove.npy If users are unsatisfied with the result, reload the state before sorting/removing with Load function. After applying sorting/removing operation, the cache of the operations will be reset. Users cannot use undo/redo to return to even earlier states.","title":"Notes: How to go back"},{"location":"Round2/start_r2/","text":"Workflow of round 2 Specify the images and the parameters ( Detailed instructions ) Launch the main window of 3D correction ( Panel descriptions ) Perform inspections and corrections with following operations: Localize to a cell. Correct the segmentation in slice i with following operations: Merge / Delete / Division / Division-Relink / 3D Division / Insert Sort cells by sizes and Remove tiny cells . Save and load intermediate segmentation results. Export the segmentation as 2D Tiff images.","title":"Start round 2"},{"location":"Round2/start_r2/#workflow-of-round-2","text":"Specify the images and the parameters ( Detailed instructions ) Launch the main window of 3D correction ( Panel descriptions ) Perform inspections and corrections with following operations: Localize to a cell. Correct the segmentation in slice i with following operations: Merge / Delete / Division / Division-Relink / 3D Division / Insert Sort cells by sizes and Remove tiny cells . Save and load intermediate segmentation results. Export the segmentation as 2D Tiff images.","title":"Workflow of round 2"}]}